---
output-file: core.html
title: '**Downloading the Dataset and the weights of the pre trained model**'

---


<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->

### **Packages Installation**

**Download the Dataset**



**Download the Weights of the RF-DETR**



**Clone the Sam2 Model**

**Downlaod the weights of angle models**



**Download the weights of sam2**

# **RF-DETR Model for shape and arrow detection**

Metric evaluation and ploting

path of the pre-train weights and path of the image to to check the shape detection



**Convert Co-ordinates of detected objects into JSON**

# **Paddle OCR**

**saved the output in the OCRoutput folder after applying the OCR:**
1. first image saved by after applying the ocr
2. second saved the response in the JSON format of the OCR applied image.

Get the bbox of the text extracted by the paddleOCR from the json file







































































# **Spatial Relationship**

Main pipeline where find out the main relationship of the arrows with the shapes and the detections of the arrow's endpoints

::: {#cell-56 .cell quarto-private-1='{"key":"colab","value":{"base_uri":"https://localhost:8080/"}}' outputId='4e94c8e9-9a43-4b09-ce5f-c1c2ce32dd56'}
``` {.python .cell-code}
import cv2
import matplotlib.pyplot as plt
from skimage.morphology import skeletonize
from collections import deque
import itertools
import math

# ==============================================================================
# ---------- HELPER FUNCTIONS  ----------
# ==============================================================================

def show_image(title, img, cmap=None):
    plt.figure(figsize=(4, 4))
    if len(img.shape) == 2: plt.imshow(img, cmap=cmap or "gray")
    else: plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
    plt.title(title); plt.axis("off"); plt.show()

def crop_image_region(image, top_left, bottom_right):
    x1, y1 = map(int, map(round, top_left))
    x2, y2 = map(int, map(round, bottom_right))
    return image[y1:y2, x1:x2]

def convert_to_binary_mask(cropped_img):
    if cropped_img.size == 0:
        return np.array([], dtype=np.uint8)
    gray = cv2.cvtColor(cropped_img, cv2.COLOR_BGR2GRAY)
    blurred = cv2.GaussianBlur(gray, (3,3), 0)

    edges = cv2.Canny(blurred, threshold1=30, threshold2=100)

    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3,3))
    closed = cv2.morphologyEx(edges, cv2.MORPH_CLOSE, kernel, iterations=1)

    _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    if np.mean(thresh) > 127:
        thresh = cv2.bitwise_not(thresh)
    combined_mask = cv2.bitwise_or(closed, thresh)
    return combined_mask


def connect_dotted_simple_morph(binary_mask, kernel_size=5, iterations=2):

    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_size, kernel_size))
    closed_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_CLOSE, kernel, iterations=1)
    connected_mask = cv2.dilate(closed_mask, kernel, iterations=iterations)
    return connected_mask


def find_farthest_points_in_contour(contour):
    max_dist_sq, best_pair = -1, None
    points = contour.squeeze(axis=1)
    if len(points) < 2: return None
    for p1, p2 in itertools.combinations(points, 2):
        dist_sq = (p1[0] - p2[0])**2 + (p1[1] - p2[1])**2
        if dist_sq > max_dist_sq: max_dist_sq, best_pair = dist_sq, (tuple(p1), tuple(p2))
    return best_pair

def interpolate_dashed_arrows(binary_mask, max_gap_ratio=0.5, thickness=2):
    contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    contours = [c for c in contours if cv2.contourArea(c) > 3]

    if len(contours) < 2:
        return binary_mask

    dash_endpoints = []
    for cnt in contours:
        end_pts = find_farthest_points_in_contour(cnt)
        if end_pts:
            dash_endpoints.append(list(end_pts))

    dash_lengths = [math.dist(ep[0], ep[1]) for ep in dash_endpoints if ep]
    if not dash_lengths:
        return binary_mask
    max_connect_dist = np.median(dash_lengths) * (1 + max_gap_ratio)

    output_mask = binary_mask.copy()

    for i, eps1 in enumerate(dash_endpoints):
        for ep1 in eps1:
            min_dist = float('inf')
            best_ep = None
            for j, eps2 in enumerate(dash_endpoints):
                if i == j:
                    continue
                for ep2 in eps2:
                    dist = math.dist(ep1, ep2)
                    if dist < min_dist:
                        min_dist = dist
                        best_ep = ep2
            if best_ep and min_dist < max_connect_dist:
                cv2.line(output_mask, ep1, best_ep, 255, thickness=thickness)

    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (6, 5))
    output_mask = cv2.dilate(output_mask, kernel, iterations=2)

    return output_mask


def extract_skeleton(binary_mask):
    return skeletonize(binary_mask > 0).astype(np.uint8) * 255


def get_skeleton_graph_nodes(skeleton):
    endpoints, junctions = [], []
    h, w = skeleton.shape
    padded_skeleton = np.pad(skeleton, 1, 'constant')
    for y_pad in range(1, h + 1):
        for x_pad in range(1, w + 1):
            if padded_skeleton[y_pad, x_pad] > 0:
                num_neighbors = np.sum(padded_skeleton[y_pad-1:y_pad+2, x_pad-1:x_pad+2] > 0) - 1
                if num_neighbors == 1: endpoints.append((x_pad - 1, y_pad - 1))
                elif num_neighbors > 2: junctions.append((x_pad - 1, y_pad - 1))
    return endpoints, junctions


def find_farthest_points_euclidean(binary_mask):
    contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    if not contours: return []
    all_points = np.vstack([cnt.squeeze(axis=1) for cnt in contours if cnt.ndim > 2])
    if len(all_points) < 2: return []
    return find_farthest_points_in_contour(np.array(all_points).reshape(-1, 1, 2))


def check_bbox_intersection(box1_tl, box1_br, box2_tl, box2_br):
    return not (box1_br[0] < box2_tl[0] or box1_tl[0] > box2_br[0] or box1_br[1] < box2_tl[1] or box1_tl[1] > box2_br[1])


def simple_bridge_by_interpolation(binary_mask, ocr_bbox_local, thickness=1):

    h, w = binary_mask.shape[:2]
    x1, y1, x2, y2 = map(int, ocr_bbox_local)
    x1, y1 = max(0, x1), max(0, y1)
    x2, y2 = min(w, x2), min(h, y2)
    if x2 <= x1 or y2 <= y1:
        return binary_mask.copy()

    mask_no_text = binary_mask.copy()
    mask_no_text[y1:y2, x1:x2] = 0

    pts = np.column_stack(np.where(mask_no_text > 0))
    if pts.size == 0:
        return binary_mask.copy()

    left_pts = pts[pts[:, 1] < x1]
    right_pts = pts[pts[:, 1] > x2]

    if left_pts.size and right_pts.size:
        left_idx = np.argmax(left_pts[:, 1])
        right_idx = np.argmin(right_pts[:, 1])
        left_p = (int(left_pts[left_idx, 1]), int(left_pts[left_idx, 0]))
        right_p = (int(right_pts[right_idx, 1]), int(right_pts[right_idx, 0]))
        p1, p2 = left_p, right_p
    else:
        top_pts = pts[pts[:, 0] < y1]
        bottom_pts = pts[pts[:, 0] > y2]
        if top_pts.size and bottom_pts.size:
            top_idx = np.argmax(top_pts[:, 0])
            bot_idx = np.argmin(bottom_pts[:, 0])
            top_p = (int(top_pts[top_idx, 1]), int(top_pts[top_idx, 0]))
            bot_p = (int(bottom_pts[bot_idx, 1]), int(bottom_pts[bot_idx, 0]))
            p1, p2 = top_p, bot_p
        else:
            coords = np.column_stack((pts[:,1], pts[:,0]))
            max_d = -1; best = None
            for i in range(len(coords)):
                for j in range(i+1, len(coords)):
                    d = (coords[i,0]-coords[j,0])**2 + (coords[i,1]-coords[j,1])**2
                    if d > max_d:
                        max_d = d
                        best = (tuple(coords[i].tolist()), tuple(coords[j].tolist()))
            if not best:
                return binary_mask.copy()
            p1, p2 = best

    out = mask_no_text.copy()
    dist = int(math.hypot(p2[0]-p1[0], p2[1]-p1[1]))
    if dist < 2:
        cv2.line(out, p1, p2, 255, thickness=max(1, thickness))
        return out

    n = max(dist, 2)
    xs = np.linspace(p1[0], p2[0], n)
    ys = np.linspace(p1[1], p2[1], n)
    for x, y in zip(xs, ys):
        cx, cy = int(round(x)), int(round(y))
        x0, x1_ = max(0, cx - thickness), min(w, cx + thickness + 1)
        y0, y1_ = max(0, cy - thickness), min(h, cy + thickness + 1)
        out[y0:y1_, x0:x1_] = 255

    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
    out = cv2.dilate(out, kernel, iterations=1)
    return out

def bbox_iou(boxA, boxB):
    xA = max(boxA[0], boxB[0])
    yA = max(boxA[1], boxB[1])
    xB = min(boxA[2], boxB[2])
    yB = min(boxA[3], boxB[3])
    interArea = max(0, xB - xA) * max(0, yB - yA)
    if interArea == 0:
        return 0.0
    boxAArea = (boxA[2] - boxA[0]) * (boxA[3] - boxA[1])
    boxBArea = (boxB[2] - boxB[0]) * (boxB[3] - boxB[1])
    return interArea / float(boxAArea + boxBArea - interArea)

def pixel_level_ocr_interference(binary_arrow_mask, ocr_bbox, crop_origin, coverage_threshold=0.05):
    crop_x1, crop_y1 = crop_origin
    h, w = binary_arrow_mask.shape

    ox1, oy1, ox2, oy2 = ocr_bbox
    local_x1 = max(0, int(ox1 - crop_x1))
    local_y1 = max(0, int(oy1 - crop_y1))
    local_x2 = min(w, int(ox2 - crop_x1))
    local_y2 = min(h, int(oy2 - crop_y1))

    if local_x1 >= local_x2 or local_y1 >= local_y2:
        return False

    arrow_pixels = np.count_nonzero(binary_arrow_mask)
    if arrow_pixels == 0:
        return False

    overlap_region = binary_arrow_mask[local_y1:local_y2, local_x1:local_x2]
    overlap_count = np.count_nonzero(overlap_region)
    coverage_ratio = overlap_count / arrow_pixels
    return coverage_ratio > coverage_threshold

def mask_overlapping_ocr_regions(binary_mask, ocr_intrusions, crop_origin):
    mask = binary_mask.copy()
    crop_x1, crop_y1 = crop_origin
    h, w = mask.shape

    for ocr in ocr_intrusions:
        ox1, oy1, ox2, oy2 = ocr['bbox']
        local_x1 = max(0, int(ox1 - crop_x1))
        local_y1 = max(0, int(oy1 - crop_y1))
        local_x2 = min(w, int(ox2 - crop_x1))
        local_y2 = min(h, int(oy2 - crop_y1))
        if local_x1 < local_x2 and local_y1 < local_y2:
            mask[local_y1:local_y2, local_x1:local_x2] = 0
    return mask

def match_arrowhead_to_endpoint(arrowhead_bboxes, endpoints, crop_origin):

    if not arrowhead_bboxes:
        return None

    crop_x, crop_y = crop_origin
    arrowhead_centers = []
    for tl, br in arrowhead_bboxes:
        cx = (tl[0] + br[0]) / 2 - crop_x
        cy = (tl[1] + br[1]) / 2 - crop_y
        arrowhead_centers.append((cx, cy))

    for center in arrowhead_centers:
        for ep in endpoints:

            if abs(ep[0] - center[0]) < 15 and abs(ep[1] - center[1]) < 12:
                return ep
    return None

# =================================================================================
# ---------- FOR INTERSECTING ARROWS ----------
# =================================================================================

def bfs_get_path(skeleton, start_xy, end_xy):


    h, w = skeleton.shape
    start_rc, end_rc = (start_xy[1], start_xy[0]), (end_xy[1], end_xy[0])

    if not (0 <= start_rc[0] < h and 0 <= start_rc[1] < w and skeleton[start_rc] > 0): return None
    if not (0 <= end_rc[0] < h and 0 <= end_rc[1] < w and skeleton[end_rc] > 0): return None

    q = deque([(start_rc, [start_xy])])
    visited = {start_rc}

    while q:
        (r, c), path = q.popleft()

        if (r, c) == end_rc:
            return path

        for dr, dc in itertools.product([-1, 0, 1], repeat=2):
            if dr == 0 and dc == 0: continue
            nr, nc = r + dr, c + dc

            if 0 <= nr < h and 0 <= nc < w and skeleton[nr, nc] > 0 and (nr, nc) not in visited:
                visited.add((nr, nc))
                new_path = path + [(nc, nr)]
                q.append(((nr, nc), new_path))

    return None

def find_best_arrow_by_straightness(binary_mask, min_path_length=20):

    skeleton = extract_skeleton(binary_mask)
    if np.count_nonzero(skeleton) < min_path_length:
        return None

    endpoints, _ = get_skeleton_graph_nodes(skeleton)

    if len(endpoints) < 2:
        return find_farthest_points_euclidean(binary_mask)

    candidate_paths = []
    for p1, p2 in itertools.combinations(endpoints, 2):
        path = bfs_get_path(skeleton, p1, p2)

        if path and len(path) >= min_path_length:
            path_length = len(path)
            euclidean_dist = math.dist(p1, p2)

            straightness = euclidean_dist / path_length

            score = path_length * straightness

            candidate_paths.append({
                "endpoints": [p1, p2],
                "score": score,
                "length": path_length
            })

    if not candidate_paths:
        return None

    best_path = max(candidate_paths, key=lambda x: x['score'])
    return best_path['endpoints']


## ==============================================================================
# ----------   MAIN PIPELINE FUNCTION  ----------
# ==============================================================================

def skeleton_has_cycle(skeleton):
    h, w = skeleton.shape
    visited = np.zeros((h, w), dtype=bool)

    def neighbors(r, c):
        for dr in [-1, 0, 1]:
            for dc in [-1, 0, 1]:
                if dr == 0 and dc == 0:
                    continue
                nr, nc = r + dr, c + dc
                if 0 <= nr < h and 0 <= nc < w and skeleton[nr, nc] > 0:
                    yield nr, nc

    def dfs(r, c, pr, pc):
        visited[r, c] = True
        for nr, nc in neighbors(r, c):
            if not visited[nr, nc]:
                if dfs(nr, nc, r, c):
                    return True
            elif (nr, nc) != (pr, pc):
                return True
        return False

    for y in range(h):
        for x in range(w):
            if skeleton[y, x] > 0 and not visited[y, x]:
                if dfs(y, x, -1, -1):
                    return True
    return False


def find_farthest_geodesic_endpoints(skeleton):
    endpoints, _ = get_skeleton_graph_nodes(skeleton)
    if len(endpoints) < 2: return None
    max_length, best_pair = -1, None
    for p1, p2 in itertools.combinations(endpoints, 2):
        path = bfs_get_path(skeleton, p1, p2)
        if path and len(path) > max_length:
            max_length, best_pair = len(path), (p1, p2)
    return best_pair


def dilate_ocr_regions(binary_mask, ocr_intrusions, crop_origin,
                       vert_expand=1, horiz_expand=1,
                       vert_iterations=1, horiz_iterations=1,
                       erosion_kernel_size=3, erosion_iterations=1):
    mask = np.zeros_like(binary_mask)
    crop_x1, crop_y1 = crop_origin
    h, w = mask.shape
    for ocr in ocr_intrusions:
        ox1, oy1, ox2, oy2 = ocr['bbox']
        local_x1 = max(0, int(ox1 - crop_x1))
        local_y1 = max(0, int(oy1 - crop_y1))
        local_x2 = min(w, int(ox2 - crop_x1))
        local_y2 = min(h, int(oy2 - crop_y1))
        if local_x1 < local_x2 and local_y1 < local_y2:
            mask[local_y1:local_y2, local_x1:local_x2] = 255

    vert_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, vert_expand))
    horiz_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (horiz_expand, 1))

    mask = cv2.dilate(mask, vert_kernel, iterations=vert_iterations)
    mask = cv2.dilate(mask, horiz_kernel, iterations=horiz_iterations)

    combined = cv2.bitwise_or(binary_mask, mask)

    erosion_kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,
                                               (erosion_kernel_size, erosion_kernel_size))
    combined = cv2.erode(combined, erosion_kernel, iterations=erosion_iterations)

    return combined


def find_skeleton_points_on_bbox(skeleton, bbox_tl, bbox_br, margin=2):
    points = np.column_stack(np.where(skeleton > 0))
    x_min, y_min = bbox_tl
    x_max, y_max = bbox_br
    candidate_points = []
    for y, x in points:
        near_left = abs(x - x_min) <= margin and y_min <= y <= y_max
        near_right = abs(x - x_max) <= margin and y_min <= y <= y_max
        near_top = abs(y - y_min) <= margin and x_min <= x <= x_max
        near_bottom = abs(y - y_max) <= margin and x_min <= x <= x_max
        if near_left or near_right or near_top or near_bottom:
            candidate_points.append((x, y))
    return candidate_points


def debug_stage(image, detections, ocr_results):
    vectors = []
    arrow_labels = ["dashed-arrow", "dotted-arrow", "solid-arrow"]
    non_arrow_labels = ["Diamond"]

    arrows = [d for d in detections if d[0] in arrow_labels]
    interfering_objects = [d for d in detections if d[0] in non_arrow_labels]

    # ... keep the rest of debug_stage body exactly as you have it ...

    return vectors


# Example usage (for documentation only; not executed by nbdev_docs):
# image = cv2.imread(file_path)
# detections = detections_list
# vectors = debug_stage(image, detections, final_processed_data)
# print("\n=== Results from Full Pipeline ===")
# for v in vectors:
#     print(f"Arrow: Tail={v['tail']} â†’ Head={v['head']} -> Label={v['label']}")
```

::: {.cell-output .cell-output-stdout}
```

=== Results from Full Pipeline ===
```
:::
:::


::: {#cell-57 .cell quarto-private-1='{"key":"colab","value":{"base_uri":"https://localhost:8080/","height":1000}}' outputId='a7aee19d-2bb5-46cf-b52c-1e03d8818e25'}
``` {.python .cell-code}
from scipy.interpolate import splprep, splev

def show_image(title, img, cmap=None):
    plt.figure(figsize=(12, 12))
    if len(img.shape) == 2:
        plt.imshow(img, cmap=cmap or "gray")
    else:
        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
    plt.title(title, fontsize=16)
    plt.axis("off")
    plt.show()

def point_to_bbox_distance(point, top_left, bottom_right):
    px, py = point
    x1, y1 = top_left
    x2, y2 = bottom_right

    if x1 <= px <= x2 and y1 <= py <= y2:
        return 0.0

    dx = max(x1 - px, 0, px - x2)
    dy = max(y1 - py, 0, py - y2)
    return math.sqrt(dx*dx + dy*dy)

def nearest_point_on_bbox(point, top_left, bottom_right):
    px, py = point
    x1, y1 = top_left
    x2, y2 = bottom_right
    cx = min(max(px, x1), x2)
    cy = min(max(py, y1), y2)
    return (int(round(cx)), int(round(cy)))

def find_nearest_shape_bbox(point, shapes, max_distance=None):
    if not shapes:
        return None, None, None

    min_dist = float('inf')
    nearest_shape = None
    nearest_pt = None

    for shape in shapes:
        label, top_left, bottom_right = shape
        pt_on_bbox = nearest_point_on_bbox(point, top_left, bottom_right)
        dist = math.hypot(pt_on_bbox[0] - point[0], pt_on_bbox[1] - point[1])

        if dist < min_dist:
            min_dist = dist
            nearest_shape = shape
            nearest_pt = pt_on_bbox

    if max_distance is not None and min_dist > max_distance:
        return None, None, None

    return nearest_shape, nearest_pt, min_dist

def draw_connections_on_image(image, connections):
    vis_image = image.copy()

    ARROW_COLOR = (0, 255, 0)        # green
    HEAD_COLOR = (255, 0, 0)         # red
    TAIL_COLOR = (0, 255, 255)       # cyan
    CONNECTION_COLOR = (255, 0, 255) # magenta

    for conn in connections:
        head = conn["head"]
        tail = conn["tail"]

        cv2.arrowedLine(vis_image, tail, head, ARROW_COLOR, 2, tipLength=0.04)

        cv2.circle(vis_image, head, 8, HEAD_COLOR, -1)
        cv2.circle(vis_image, tail, 8, TAIL_COLOR, -1)

        if conn.get("head_connected_to") is not None:
            head_pt = conn.get("head_connection_point")
            if head_pt is None:
                _, tl, br = conn["head_connected_to"]
                head_pt = (int((tl[0] + br[0]) / 2), int((tl[1] + br[1]) / 2))
            cv2.line(vis_image, head, head_pt, CONNECTION_COLOR, 2, cv2.LINE_AA)
            cv2.circle(vis_image, head_pt, 5, CONNECTION_COLOR, -1)

        if conn.get("tail_connected_to") is not None:
            tail_pt = conn.get("tail_connection_point")
            if tail_pt is None:
                _, tl, br = conn["tail_connected_to"]
                tail_pt = (int((tl[0] + br[0]) / 2), int((tl[1] + br[1]) / 2))
            cv2.line(vis_image, tail, tail_pt, CONNECTION_COLOR, 2, cv2.LINE_AA)
            cv2.circle(vis_image, tail_pt, 5, CONNECTION_COLOR, -1)

    return vis_image

def establish_connections(vectors, all_detections):
    labels_to_exclude = ["dashed-arrow", "dotted-arrow", "solid-arrow", "arrow_head"]
    shape_detections = [d for d in all_detections if d[0] not in labels_to_exclude]

    connections = []

    for vector in vectors:
        head_point = vector["head"]
        tail_point = vector["tail"]

        MAX_CONNECTION_DISTANCE = 44

        head_shape, head_pt_on_bbox, head_dist = find_nearest_shape_bbox(
            head_point, shape_detections, max_distance=MAX_CONNECTION_DISTANCE
        )
        tail_shape, tail_pt_on_bbox, tail_dist = find_nearest_shape_bbox(
            tail_point, shape_detections, max_distance=MAX_CONNECTION_DISTANCE
        )

        connections.append({
            "head": head_point,
            "tail": tail_point,
            "head_connected_to": head_shape,
            "head_connection_point": head_pt_on_bbox,
            "head_connection_dist": head_dist,
            "tail_connected_to": tail_shape,
            "tail_connection_point": tail_pt_on_bbox,
            "tail_connection_dist": tail_dist,
            "original_label": vector.get("label", "")
        })

    return connections

# Example usage (docs only; not executed by nbdev_docs):
# arrow_connections = establish_connections(vectors, detections)
# print("\n--- ARROW CONNECTION RESULTS ---")
# for i, conn in enumerate(arrow_connections):
#     head_label = conn['head_connected_to'][0] if conn['head_connected_to'] else 'None'
#     tail_label = conn['tail_connected_to'][0] if conn['tail_connected_to'] else 'None'
#     print(
#         f"Arrow {i} ({conn['original_label']}):\n"
#         f"  - TAIL at {conn['tail']} connects to -> {tail_label}\n"
#         f"  - HEAD at {conn['head']} connects to -> {head_label}\n"
#     )
#
# visualization_image = draw_connections_on_image(image, arrow_connections)
# show_image("Final Arrow Connections", visualization_image)
```

::: {.cell-output .cell-output-stdout}
```

--- ARROW CONNECTION RESULTS ---
```
:::

::: {.cell-output .cell-output-display}
![](00_core_files/figure-html/cell-42-output-2.png){}
:::
:::


# **Angle Prediction of shapes**

**Run once when the notebook is run from start**

# **Dominant Color Prediction**

# **Final JSON Output**

# **MAP**

```
# This is formatted as code
```

**Mean Average Precision of the RF-DETR model**

**Verifying the Arrow connections for finding the algorithm accuracy**

Confusion metrix on the Output of the algorithm of arrow connections

correct

---

### DiagramGenerator

>      DiagramGenerator (json_data)

*Initialize self.  See help(type(self)) for accurate signature.*



